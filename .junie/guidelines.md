# Оркестратор ETL‑процессов на базе Apache Airflow — Project Guidelines for Junie

Этот документ содержит концентрированную информацию для разработки и поддержки проекта **Оркестратор ETL‑процессов на базе Apache Airflow** (репозиторий `up-distributor-airflow`). Он ориентирован на опытных разработчиков и фиксирует правила, которые следует считать авторитетными при работе над задачами в этом репозитории.

> Дисклеймер. Описанные подходы и примеры конфигурации ориентированы на внутреннее использование и могут требовать адаптации под конкретное окружение Airflow и инфраструктуру данных. Никогда не храните пароли, токены и другие секреты в коде, DAG‑файлах или README — используйте переменные окружения и секрет‑хранилища.

---

## 1. Обзор проекта

- **Тип**: Оркестрация ETL‑процессов на базе Apache Airflow.
- **Основная задача**: чтение данных из PostgreSQL, преобразование записей по конфигурации и публикация сообщений в брокеры (RabbitMQ/Kafka/Redis) или обратная загрузка в БД.
- **Основные сущности**:
    - **DAG-и** в каталоге `dags/` описывают конкретные сценарии (ingest/load/stat/trigger) для разных источников и витрин.
    - **Config/Config-like settings**: словари `settings` в DAG‑файлах, инкапсулируемые в класс `Config` (`src/utils/config.py`).
    - **Services** в `src/services/` реализуют бизнес‑логику (ingestion, loading, statistics, trigger).
    - **Repositories** в `src/database/repositories/` обеспечивают доступ к PostgreSQL, скрывая детали SQL/подключений.
    - **Message clients** в `src/message_broker/` предоставляют унифицированный интерфейс работы с брокерами.

Архитектурно проект стремится к разделению ответственности: DAG-и только собирают настройки и дергают сервисы, а сама логика находится в Python‑модулях `src/`.

---

## 2. Сборка, запуск и конфигурация

### 2.1. Базовые режимы запуска

Проект подразумевает два основных режима эксплуатации: **production** и **test/dev** (условные режимы для разных окружений Airflow). Все сценарии завязаны на Docker Compose.

#### Production

1. На корне проекта создайте файл `.env.prod` на основе шаблона `.env` (см. README, актуальный набор переменных окружения зависит от инфраструктуры).
2. Соберите образы:

   ```powershell
   docker compose build
   ```

3. Поднимите окружение:

   ```powershell
   docker compose up -d
   ```

#### Test/Dev окружение

1. На корне создайте `.env.test` или `.env.dev` на базе `.env`.
2. Используйте профиль test с дополнительным override‑файлом:

   ```powershell
   docker compose --env-file .env.test -f docker-compose.yml -f "docker/config-envs/test/docker-compose.override.yml" build

   docker compose --env-file .env.test -f docker-compose.yml -f "docker/config-envs/test/docker-compose.override.yml" up -d
   ```

Airflow webserver/scheduler поднимаются внутри docker‑композ‑стека; DAG‑и автоматически подхватываются из каталога `dags/` контейнера.

### 2.2. Ключевые переменные окружения

Фактический список параметров лучше смотреть в `.env`‑шаблоне и `README.md`, но при изменении DAG‑ов и сервисов нужно помнить о следующих группах переменных:

- **PostgreSQL (EDU/EDI и др.)**:
    - `DB_*_HOST`, `DB_*_PORT`, `DB_*_USER`, `DB_*_PASSWORD`, `DB_*_NAME`, `DB_*_SCHEMA_NAME` — используются в DAG‑ах и внутри `Config` для построения connection‑строк и fully‑qualified имен таблиц.
- **Брокеры (RabbitMQ/Kafka/Redis)**:
    - `RABBITMQ_EDI_HOST`, `RABBITMQ_EDI_PORT`, `RABBITMQ_EDI_USER`, `RABBITMQ_EDI_PASS` и аналоги для других сред.
    - `REDIS_*_URL` — для Redis‑клиента.
- **Прочее**:
    - Переменные для логирования, окружения Airflow и т.п., задаются в `.env` и/или `config/airflow.cfg`.

Если вы добавляете новый DAG, требующий дополнительных параметров, придерживайтесь существующей схемы именования и используйте функции `get_str`/`get_int` из `src/utils/env.py` вместо прямого доступа к `os.getenv`.

### 2.3. Как связаны DAG и сервисы

Типичный DAG (например, `dags/new_asin_keyword/new_asin_keyword_in.py`):

- Описывает `default_args` Airflow.
- Собирает словарь `settings` с ключами:
    - общие параметры (`project_name`, `dag_id`, `schedule`, `source` и т.д.);
    - `broker`‑подсекция (тип и настройки брокера);
    - `database`‑подсекция (таблицы, колонки, batch‑размер и др.).
- В `PythonOperator` вызывает функцию, которая создаёт сервис через `ServiceFactory.create_ingestion_service(settings)` и вызывает метод `ingest_data()`.

Таким образом, при изменении бизнес‑правил сначала правится конфигурация `settings`, а затем — поведение соответствующего сервиса/репозитория.

---

## 3. Архитектура и важные модули

### 3.1. Config и конфигурационные словари

- Класс `Config` (`src/utils/config.py`) — центральная точка доступа к настройкам DAG‑а.
- В конструктор передаётся словарь `settings` из DAG‑файла.
- Реализует множество `@property`, инкапсулирующих структуру `settings`:
    - broker_* (тип брокера, topic, параметры подключения для Kafka/Rabbit/Redis);
    - database_* (таблицы source/target, conflict keys, order/version columns, batch size, queue size limit);
    - вспомогательные методы для alias‑ов столбцов, маппингов и пользовательских функции (`map_before_kafka_produce`, `modify_data_function`, `message_filter`).

Рекомендации:

- Новые настройки лучше добавлять как property‑методы в `Config`, а не распаковывать словарь вручную в сервисе.
- Для дополнительных разделов в `settings` сохраняйте существующий стиль вложенных dict‑ов (`database.source`, `database.target`, `broker` и т.д.).
- Избегайте прямых обращений к `settings["..."]` в коде сервисов; используйте `Config` как слой адаптации.

### 3.2. Сервисы и фабрика сервисов

- Файл `src/factories/service_factory.py` реализует `ServiceFactory` с фабричными методами:
    - `create_ingestion_service(settings)`
    - `create_loading_service(settings)`
    - `create_stat_service(settings)`
    - `create_trigger_service(settings)`

Шаблон работы:

1. Инициализировать `Config` из `settings`.
2. Создать `Serializer` из `src/utils/serializer.py` на основе `Config` (управляет маппингом колонок, сериализацией сообщений).
3. Через `RepositoryFactory` (`src/database/repositories/repository_factory.py`) получить конкретный `GenericRepository`.
4. Через `MessageClientFactory` (`src/message_broker/factory.py`) выбрать реализацию `IMessageClient` (Kafka, RabbitMQ, Redis) по типу из `Config`.
5. Вернуть соответствующий сервис (`IngestionService`, `LoadingService`, `StatisticsService`, `TriggerService`).

При расширении функциональности избегайте внедрения прямых зависимостей на конкретные реализации брокеров или репозиториев внутрь DAG‑ов — все это должно оставаться за фабриками и сервисами.

### 3.3. Репозитории и подключение к БД

- `src/database/connection_factory.py` и `src/database/connections/` реализуют фабрики подключения к PostgreSQL.
- `src/database/repositories/` содержит:
    - базовые интерфейсы и общий `GenericRepository` для чтения/записи;
    - специализированные репозитории (например, `statistics_repository.py`, `trigger_repository.py`).

Принципы:

- SQL и работа с курсорами/connection должны оставаться в репозиториях.
- Сервисы не должны формировать SQL‑строки вручную — только вызывать методы репозиториев.
- При добавлении новых репозиториев убедитесь, что `RepositoryFactory` умеет их создавать, и не ломайте существующий интерфейс `GenericRepository` без крайней необходимости.

### 3.4. Message broker слой

- Интерфейс `IMessageClient` задаёт минимальный контракт для клиентов брокеров.
- `src/message_broker/factory.py` выбирает подходящую реализацию по `Config.broker_type`.
- Реализации:
    - Kafka (использует `kafka-python`);
    - Redis‑based брокер;
    - RabbitMQ‑совместимые брокеры (через `pika` или Airflow‑провайдеры, в зависимости от конкретной реализации).

Если добавляете новый тип брокера, придерживайтесь следующего:

1. Расширяйте только фабрику и реализацию клиента, не меняя интерфейс `IMessageClient` без веских оснований.
2. В `Config` добавьте отдельные property для параметров нового брокера.
3. В DAG‑ах учитывайте тип брокера и передавайте корректную секцию `broker` в `settings`.

---

## 4. Правила разработки и стиль кода

### 4.1. Общие принципы

- Сохраняйте разделение ответственности между слоями:
    - DAG описывает оркестрацию и настройки;
    - сервисы — бизнес‑логику;
    - репозитории — SQL и работу с БД;
    - message‑clients — детали конкретного брокера.
- Не дублируйте логику: если новый DAG повторяет существующий сценарий с другими таблицами/топиками — выносите общие части в сервисы/утилиты.
- Старайтесь не завязываться на конкретные имена таблиц/топиков внутри кода сервисов: всё, что возможно, берите из `Config`.

### 4.2. Python‑стиль

- Стремитесь к PEP 8: читаемые имена, минимизация побочных эффектов, явные импорты.
- Логика, завязанная на конкретный DAG, должна быть легко читаема: избегайте "магических" чисел и строк — выносите их в `settings`.
- Для сложных конфигураций внутри DAG‑ов предпочтительны явные словари с комментариями, а не вычисляемые структуры, усложняющие отладку.

### 4.3. Работа с конфигурацией и env

- Для доступа к переменным среды используйте `src/utils/env.py` (`get_str`, `get_int` и т.д.), а не прямой `os.getenv`.
- При добавлении новых env‑переменных документируйте их в `README.md` и следите, чтобы дефолты были разумными (или явно отсутствовали, если параметр строго обязателен).

### 4.4. Логирование и отладка

- Для логирования используйте утилиты из `src/utils/logger.py` (если в проекте есть централизованная настройка) или встроенный логгер Airflow (`task_instance.log`, `logging.getLogger` с единым форматом).
- При ошибках в интеграции с брокером/БД старайтесь логировать:
    - ключевые параметры (без секретов);
    - идентификаторы задач и DAG‑ов;
    - фрагменты запросов/сообщений, достаточные для анализа.

---

## 5. Работа с DAG‑ами

### 5.1. Создание нового DAG

Рекомендуемый алгоритм:

1. Скопировать максимально близкий по смыслу существующий DAG (например, один из `local_data_*` или `new_asin_keyword_*`).
2. Обновить:
    - `project_name`, `dag_id`, `dag_description`, `schedule`, `tags`;
    - секцию `broker` (тип и параметры подключения);
    - секцию `database` (таблицы, conflict keys, колонки, batch‑размер, фильтры `conditions`).
3. Убедиться, что функция‑обёртка (`ingest_data`, `load_data` и т.п.) использует соответствующий метод фабрики (`create_ingestion_service`, `create_loading_service`, ...).
4. Проверить DAG через Airflow UI (Graph/Tree view), убедившись, что он успешно парсится и создаётся.

### 5.2. Расширение существующих DAG‑ов

- При добавлении новых условий выборки (`conditions`) используйте явную структуру из словарей с полями `column`, `operation`, `value`.
- При изменении структуры таблиц **не** вшивайте хардкод в сервисы: обновите конфигурацию `settings` и маппинги в `Config`/`Serializer`.
- Если меняете схему версионирования (`version.scale`, `order.column`), проверьте, как эти поля используются в репозитории и сервисе, чтобы не сломать инкрементальную загрузку.

---

## 6. Диагностика и отладка в рантайме

### 6.1. Типичные проблемы

1. **DAG не подхватывается Airflow**:
    - проверьте, что файл находится под `dags/` и не нарушает синтаксис Python;
    - убедитесь, что в контейнере Airflow видит этот путь (volume‑маппинг в docker‑compose).

2. **Проблемы с подключением к БД**:
    - проверьте корректность `DB_*` переменных окружения;
    - просмотрите логи соответствующего таска и контейнера с воркерами;
    - убедитесь, что host и port доступны из сети контейнера.

3. **Проблемы с брокером сообщений**:
    - проверьте `broker.type` и настройки host/port/user/password или `redis_url`;
    - убедитесь, что нужная библиотека подключена (Kafka/Rabbit/Redis) и поддерживается текущей реализацией `MessageClientFactory`;
    - проверяйте реальные топики/очереди на стороне брокера для валидации доставки.

4. **Некорректные данные в сообщениях/таблицах**:
    - проверьте маппинги колонок в `Config`/`Serializer`;
    - убедитесь, что `default_values` и функции `modify_data_function`/`message_filter` настроены корректно;
    - проанализируйте входные данные из исходной таблицы (select напрямую из PostgreSQL).

### 6.2. Полезные практики при отладке

- Локально воспроизводите часть логики за пределами Airflow, вызывая сервисы напрямую из Python‑скриптов с тем же `settings`, что и в DAG.
- Для сложных кейсов добавляйте временное детальное логирование (DEBUG‑уровень) в сервисах и клиентах брокеров, не забывая чистить/упрощать лог после завершения расследования.

---

## 7. Специфические заметки для Junie

1. Перед изменениями внимательно ознакомьтесь с `README.md` и текущими DAG‑ами, чтобы не нарушить существующие соглашения по структуре `settings`.
2. Все новые параметры конфигурации должны быть доступны через `Config` и, при необходимости, задокументированы в README или в этом файле.
3. Не выносите бизнес‑логику в DAG‑и: любые сложные преобразования данных или маршрутизация должны жить в сервисах/утилитах.
4. Избегайте создания лишних файлов: для внутренней документации используйте данный `.junie/guidelines.md`, а для пользовательской — `README.md`.
